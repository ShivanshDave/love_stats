---
title: "431 Class 10"
author: "github.com/THOMASELOVE/2019-431"
date: "2019-09-26"
output:
  beamer_presentation:
    theme: "Madrid"
    fonttheme: "structurebold"
    colortheme: "whale"
    fig_height: 5.5
    fig_caption: false
---

```{r set-options, echo=FALSE, cache=FALSE, message = FALSE}
knitr::opts_chunk$set(comment=NA)
options(width = 55)
```

## Today's Agenda (Notes, Chapters 11-13)

1. Measuring Association with Correlations
    - Pearson and Spearman approaches
    - Thinking about the impact of transformations
2. Adding a categorical predictor (factor) to a model
    - Using `fct_recode` from `forcats` (tidyverse)
    - Interpreting an indicator variable regression

## Today's Packages and Loading the `VHL` Data

```{r load_packages, message = FALSE}
library(magrittr); library(janitor); library(patchwork)
library(broom); library(tidyverse)
```

```{r load_data, message = FALSE}
VHL <- read_csv("vonHippel-Lindau.csv") 
```

### `VHL` Variables

- `p.ne` = plasma norepinephrine (pg/ml)
- `tumorvol` = tumor volume (ml)
- `disease` = 1 for patients with multiple endocrine neoplasia type 2
- `disease` = 0 for patients with von Hippel-Lindau disease

## Model 1

```{r}
model1 <- lm(p.ne ~ tumorvol, data = VHL)

tidy(model1, conf.int = TRUE, conf.level = 0.9) %>%
  select(term, estimate, conf.low, conf.high) %>%
  knitr::kable(digits = 2)

glance(model1) %>% select(r.squared, sigma) %>%
  knitr::kable(digits = 2)
```

## Residuals from `model1`

```{r}
model1_aug <- augment(model1)

head(model1_aug,3)
```

## Predicting `p.ne` using `tumorvol`

```{r, echo=FALSE}
ggplot(VHL, aes(x = tumorvol, y = p.ne)) +
  geom_point(size = 3) +
  geom_smooth(method="lm", se=FALSE, col = "red") +
  theme_bw() +
  geom_text(x = 450, y = 2700, col = "blue", size = 5,
            label = paste("Pearson r = ", 
                          signif(cor(VHL$tumorvol, VHL$p.ne),2))) +
  geom_text(x = 450, y = 2500, col = "red", size = 5,
            label = paste("Predicted p.ne = ", 
                          round(model1$coefficients[1],0), 
                          " + ", 
                          round(model1$coefficients[2],2), 
                          "tumorvol")) +
  labs(title = "Association of p.ne with tumor volume",
       x = "Tumor Volume (ml)", y = "Plasma Norepinephrine (pg/ml)")
```


## The Spearman Rank Correlation

The Spearman rank correlation coefficient assesses how well the association between X and Y can be described using a **monotone function** even if that relationship is not linear. 

- A monotone function preserves order - that is, Y must either be strictly increasing as X increases, or strictly decreasing as X increases.
- A Spearman correlation of 1.0 indicates simply that as X increases, Y always increases.
- Like the Pearson correlation, the Spearman correlation is dimension-free, and falls between -1 and +1.
- A positive Spearman correlation corresponds to an increasing (but not necessarily linear) association between X and Y, while a negative Spearman correlation corresponds to a decreasing (but again not necessarily linear) association.

## Monotone Association (Source: Wikipedia)

```{r spearmanpic1-fig, out.width = '90%', fig.align = "center", echo = FALSE}
knitr::include_graphics("images/spearmanpic1.png")
```

## Spearman correlation reacts less to outliers

```{r spearmanpic4-fig, out.width = '90%', fig.align = "center", echo = FALSE}
knitr::include_graphics("images/spearmanpic4.png")
```

## Our Key Scatterplot again

```{r, echo=FALSE}
ggplot(VHL, aes(x = tumorvol, y = p.ne)) +
  geom_point(size = 3) +
  geom_smooth(method="lm", se=FALSE, col = "red") +
  geom_smooth(method = "loess", se = FALSE, col = "blue") +
  theme_bw() +
  geom_text(x = 550, y = 2700, col = "red", size = 6,
           label = paste("Pearson r = ", signif(cor(VHL$tumorvol, VHL$p.ne),2))) +
  geom_text(x = 550, y = 2500, col = "blue", size = 6,
           label = paste("Spearman r = ", signif(cor(VHL$tumorvol, VHL$p.ne, method="spearman"),2))) +
  labs(title = "Association of p.ne with tumor volume",
       x = "Tumor Volume (ml)", y = "Plasma Norepinephrine (pg/ml)")
```

# Can we transform X or Y to get to something more linear?

## Using the `log` transform to spread out the Volumes

```{r, echo=FALSE}
ggplot(VHL, aes(x = log(tumorvol), y = p.ne)) +
  geom_point(size = 3) +
  geom_smooth(method = "loess", col = "navy") +
  theme_bw() +
  labs(title = "Association of p.ne with log(tumor volume)",
       x = "Natural logarithm of Tumor Volume (ml)", y = "Plasma Norepinephrine (pg/ml)")
```

## Does a `log-log` model seem like a good choice?

```{r scatter_of_log-log, echo=FALSE}
ggplot(VHL, aes(x = log(tumorvol), y = log(p.ne))) +
  geom_point(size = 3) +
  geom_smooth(method = "loess", col = "navy") +
  theme_bw() +
  labs(title = "Association of log(p.ne) with log(tumorvol)",
       x = "Log of Tumor Volume (ml)", y = "Log of Plasma Norepinephrine (pg/ml)")
```

## Linear Model for p.ne using log(tumor volume)

```{r scatter_4_with_lm, echo=FALSE}
ggplot(VHL, aes(x = log(tumorvol), y = p.ne)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", col = "red") +
  theme_bw() +
  labs(title = "Association of p.ne with log(tumorvol)",
       x = "Natural logarithm of Tumor Volume (ml)", y = "Plasma Norepinephrine (pg/ml)")
```

## Fitting the m1log model (p.ne using log(tumorvol))

```{r}
m1log <- lm(p.ne ~ log(tumorvol), data = VHL)

tidy(m1log, conf.int = TRUE, conf.level = 0.90) %>% 
  select(term, estimate, std.error, conf.low, conf.high) %>%
  knitr::kable(digits = 2)
```

## Glancing at the model fit

```{r}
m1log <- lm(p.ne ~ log(tumorvol), data = VHL)

glance(m1log) %>%
  select(r.squared, adj.r.squared, sigma) %>% 
  knitr::kable(digits = 3)
```

## Summarizing the model's fit

```{r m1log-fig, out.width = '90%', fig.align = "center", echo = FALSE}
knitr::include_graphics("images/m1log.png")
```

## Residuals from `m1log`

```{r}
m1log_aug <- augment(m1log)

head(m1log_aug,3)
```

## `m1log` residuals: Normally distributed?

```{r, echo = FALSE, fig.align = 'center'}
p1 <- ggplot(model1_aug, aes(sample = .resid)) +
  geom_qq(col = "salmon") + geom_qq_line(col = "red") + 
  theme_bw() + 
  labs(title = "Original Model 1", y = "model1 residuals")

p2 <- ggplot(m1log_aug, aes(sample = .resid)) +
  geom_qq(col = "slateblue") + geom_qq_line(col = "red") + 
  theme_bw() + 
  labs(title = "Model m1log", y = "m1log residuals")

p3 <- ggplot(model1_aug, aes(x = "", y = .resid)) +
  geom_violin() + 
  geom_boxplot(width = 0.3, fill = "salmon") +
  theme_bw() + coord_flip() +
  labs(title = "Original Model 1", 
                    y = "model1 residuals")

p4 <- ggplot(m1log_aug, aes(x = "", y = .resid)) +
  geom_violin() + 
  geom_boxplot(width = 0.3, fill = "slateblue") +
  theme_bw() + coord_flip() +
  labs(title = "Model m1log", 
                    y = "m1log residuals")

gridExtra::grid.arrange(p1, p2, p3, p4, nrow = 2)
```

## Residuals vs. Fitted plots (model1 and m1log)

```{r, echo = FALSE}
p1 <- ggplot(model1_aug, aes(x = .fitted, y = .resid)) +
  geom_point(shape = 1, size = 3) +
  geom_smooth(method = "lm", se = FALSE, col = "black") +
  theme_bw() +
  labs(title = "Residuals vs. Fitted, model1")

p2 <- ggplot(m1log_aug, aes(x = .fitted, y = .resid)) +
  geom_point(shape = 1, size = 3) +
  geom_smooth(method = "lm", se = FALSE, col = "black") +
  theme_bw() +
  labs(title = "Residuals vs. Fitted, m1log")

p1 + p2
```


# Adding diagnosis to our model

## Creating a Factor to represent disease category

We want to add a new variable, specifically a factor, called `diagnosis`, which will take the values `von H-L` or `neoplasia`.

- Recall `disease` is a numeric 1/0 variable (0 = von H-L, 1 = neoplasia)
- Use `fct_recode` from the `forcats` package...

```{r create_diagnosis}
VHL <- VHL %>%
  mutate(diagnosis = 
           fct_recode(factor(disease), 
                      "neoplasia" = "1",
                      "von H-L" = "0")
  )
```

## Now, what does VHL look like?

```{r view_new_VHL}
VHL
```


## Compare the patients by diagnosis

```{r scatter_5_no_facets, echo=FALSE}
ggplot(VHL, aes(x = log(tumorvol), y = p.ne, col = diagnosis)) +
  geom_point(size = 3) +
  stat_smooth(method=lm, se=FALSE) +
  theme(text = element_text(size = 14)) +
  labs(title = "p.ne vs. log(tumorvol), by diagnosis",
       x = "Natural logarithm of Tumor Volume (ml)", y = "Plasma Norepinephrine (pg/ml)") +
  theme_bw()
```

## Faceted Scatterplots by diagnosis

```{r scatter_5_with_facets, echo=FALSE}
ggplot(VHL, aes(x = log(tumorvol), y = p.ne, col = diagnosis)) +
  geom_point(size = 3) +
  stat_smooth(method=lm) +
  facet_wrap(~ diagnosis) +
  guides(color = FALSE) +
  theme(text = element_text(size = 14)) +
  labs(title = "p.ne vs. log(tumorvol), by diagnosis",
       x = "Natural logarithm of Tumor Volume (ml)", y = "Plasma Norepinephrine (pg/ml)") +
  theme_bw()
```

## Separate Models by Diagnosis?

```{r}
model2_vhl <- lm(p.ne ~ log(tumorvol), 
             data = filter(VHL, diagnosis == "von H-L"))

coef(model2_vhl)

model2_neo <- lm(p.ne ~ log(tumorvol),
             data = filter(VHL, diagnosis == "neoplasia"))

coef(model2_neo)
```

Does this match our plot?

## Faceted Scatterplots by diagnosis, again

```{r, echo=FALSE}
ggplot(VHL, aes(x = log(tumorvol), y = p.ne, col = diagnosis)) +
  geom_point(size = 3) +
  stat_smooth(method=lm) +
  facet_wrap(~ diagnosis) +
  guides(color = FALSE) +
  theme(text = element_text(size = 14)) +
  labs(title = "p.ne vs. log(tumorvol), by diagnosis",
       x = "Natural logarithm of Tumor Volume (ml)", y = "Plasma Norepinephrine (pg/ml)") +
  theme_bw()
```

## Correlation Coefficients

```{r}
VHL %>%
  group_by(diagnosis) %>%
  summarize(Correlation = cor(log(tumorvol), p.ne),
            Rsquare = (cor(log(tumorvol), p.ne)^2) )
```

Does this match our plot?

## Faceted Scatterplots by diagnosis, one more time

```{r, echo=FALSE}
ggplot(VHL, aes(x = log(tumorvol), y = p.ne, col = diagnosis)) +
  geom_point(size = 3) +
  stat_smooth(method=lm) +
  facet_wrap(~ diagnosis) +
  guides(color = FALSE) +
  theme(text = element_text(size = 14)) +
  labs(title = "p.ne vs. log(tumorvol), by diagnosis",
       x = "Natural logarithm of Tumor Volume (ml)", y = "Plasma Norepinephrine (pg/ml)") +
  theme_bw()
```

## What do we predict if log(tumorvol) = 3?

`log(tumorvol)` = 3 implies `tumorvol` = `exp(3)` = `r exp(3)` ml.

From our `model2_vhl`, we'd predict:

- 417 + 220 (3) = 1,077 pg/nl of `p.ne` for a VHL patient with `tumorvol` = `r exp(3)` ml.

From our `model2_neo`, we'd predict:

- -476 + 345 (3) = 559 pg/nl of `p.ne` for a Neoplasia patient with `tumorvol` = `r exp(3)` ml.

## Model including two predictors

```{r model3}
model3 <- lm(p.ne ~ log(tumorvol) + diagnosis, data = VHL)
model3
```

## But this model only changes the intercept?

```{r}
coef(model3)
```

- Model for VHL is `p.ne` = 273 + 266 `log(tumorvol)`.
    - `p.ne` prediction if `log(tumorvol)` = 3 is 1,071 pg/nl.
    
- Model for neoplasia is `p.ne` = (273 - 404) + 266 `log(tumorvol)`, or -131 + 266 `log(tumorvol)`.
    - `p.ne` prediction if `log(tumorvol)` = 3 is 667 pg/nl.

Is that what we want?

## Model accounting for different slopes *and* intercepts

```{r model4}
model4 <- lm(p.ne ~ log(tumorvol) * diagnosis, data = VHL)
model4
```

## `model4` results

`p.ne` = 417 + 220 log(`tumorvol`) - 893 (`diagnosis = neoplasia`) + 125 (`diagnosis = neoplasia`)*log(`tumorvol`)

where the indicator variable (`diagnosis = neoplasia`) = 1 for neoplasia subjects, and 0 for other subjects...

- Model for `p.ne` in von H-L patients: 
    + 417 + 220 log(`tumorvol`)
- Model for `p.ne` in neoplasia patients: 
    + (417 - 893) + (220 + 125) log(`tumorvol`) 
    + -476 + 345 log(`tumorvol`)

These are our initial (separated) models, in this case.
    
## `model4` Predictions

What is the predicted `p.ne` for a single new subject with `tumorvol` = 200 ml (so log(tumorvol) = `r round(log(200),2)`) in each diagnosis category?

```{r model4predictionsneoplasia}
predict(model4, newdata = tibble(tumorvol = 200, 
        diagnosis = "neoplasia"), interval = "prediction")
```

```{r model4predictionVHL}
predict(model4, newdata = tibble(tumorvol = 200, 
        diagnosis = "von H-L"), interval = "prediction")
```

## How about the Residuals of model4?

```{r, echo = FALSE}
model4_aug <- augment(model4)

p1 <- ggplot(model4_aug, aes(x = .fitted, y = .resid)) +
  geom_point(shape = 1, size = 3, col = "blue") +
  geom_smooth(method = "lm", se = FALSE, col = "black") +
  theme_bw() +
  labs(title = "Residuals vs. Fitted, Model 4")

p2 <- ggplot(model4_aug, aes(sample = .resid)) +
  geom_qq(col = "blue") + geom_qq_line(col = "red") + 
  theme_bw() + 
  labs(title = "Model 4 Residuals", y = "Model 4 residuals")

p1 + p2
```

## Tidying the `model4` coefficients, with `broom`

```{r}
tidy(model4, conf.int = TRUE, conf.level = 0.90) %>%
  select(term, estimate, conf.low, conf.high) %>%
  knitr::kable(digits = 1)
```

## `model4`, summarized at a glance, with `broom`

```{r}
glance(model4) %>% select(r.squared, sigma, AIC)
```

Compare this to m1log...

```{r}
glance(m1log) %>% select(r.squared, sigma, AIC)
```

## Conclusions about VHL data

- Model 4, accounting for the interaction of diagnosis with the log of tumor volume, was able to account for about 29% of the variation in the plasma norepinephrine levels.

- m1log, which didn't include diagnosis but just the log of tumor volume, accounts for about 22% of the variation in plasma norepinephrine levels.

- Model 1, our original linear model, which didn't account for diagnosis and didn't fit assumptions well (using raw tumor volume) accounted for about 12% of the variation in plasma norepinephrine levels.

Can we draw a lot more from this yet?

# Small Groups!

## Group Task: Kidney Cancer Death Rates

The map on the next slide shows U.S. counties. 

- The shaded counties are in the bottom 10% of age-standardized rates for death due to cancer of the kidney/ureter for white males, in 1980-1989.

### Your Tasks

1. Describe the patterns you see in the map.
2. Speculate as to the cause of these patterns.

---

![](images/kidney-lowest.png)


# Don't look ahead, at least not yet.


---

![](images/kidney-highest.png)

## So what did we hear about today?

- The central role of linear regression in understanding associations between quantitative variables.
- The interpretation of a regression model as a prediction model.
- Assessment of key regression summaries, including residuals.
- Using `tidy`, `glance` and `augment` from `broom` to summarize the model.
- Measuring association through correlation coefficients.
- How we might think about "adjusting" for the effect of a categorical predictor on a relationship between two quantitative ones.
- How a transformation might help us "linearize" the relationship shown in a scatterplot.
- Thinking about outliers.

## Notes on the Kidney Cancer example, 1

I first asked you what you noticed about the map, in the hope that someone would point out the obvious pattern, which is that many of the countries in the Great Plains but relatively few near the coasts are shaded.

- Why might that be? Could these be the counties with more old people? Ah, but these rates are age-adjusted.
- They're mostly in rural areas: could the health care there be worse than in major cities? Or perhaps people living in rural areas have less healthy diets, or are exposed to more harmful chemicals? Maybe, but the confusing fact is that the highest 10% and the lowest 10% each show disproportionately higher rates in those Great Plains counties.

## Notes on the Kidney Cancer example, 2

- Consider a county with 100 white males. If it has even one kidney death in the 1980s, its rate is 1 per thousand per year, which is among the highest in the nation. If it has no such deaths, its rate will be 0, which is the lowest in the nation.
- The observed rates for smaller counties are *much* more variable, and hence they are more likely to be shaded, even if nothing special is truly going on.
- If a small county has an observed rate of 1 per thousand per year, it's probably random fluctuation. But if a large county (like Cuyahoga) has a very high rate, it is probably a real phenomenon.

### Source

My source for this example was Andrew Gelman and Deborah Nolan's book *Teaching Statistics: a bag of tricks* which is the source of a number of things we'll see in the course, including some of the "age guessing" example we've previously done.


